# RAG

# Задача 
 Создать RAG систему, база данных любая (в данном случае худлжестенное произведение), загркзка из pdf
 
 Использовать несколько вариантов поисковиков. Сделать трассировку

 # Стек 
 ридеры, поисковики, llm - llama
 трассировка - phoenix

 # Среда
 googlecolab

 # Результат
 
 1. VectorStoreIndex

    Время запроса 3-4с. Ответ не совсем точный, можно увеличить количество релевантных документов, но это увеличит количество отправляемых данных для ChatGPT,

    соответственно увеличит затраты количество токенов.

     запрос 1 - 6254 токенов запрос 2 - 6383 токенов
    
 3. LongContextReorder

    время запроса 2-3с ответ более точный, так как мы отправляем больше релевантных документов, так как подбор идет без участия GPT итоговое количество токенов будет меньше
    
    запрос 1 - 4876 токенов, запрос 2 - 4896 токенов
    
 4. download_llama_pack

    Данный пакет автоматически строит иерархический граф узлов (с большими родительскими узлами и меньшими дочерними узлами). Как итог,

    текст разбиваеться на более мелкие части и в запрос модели идет меньше лишней информации, следовательно меньше токенов.

    запрос 1 - 805 токенов, запрос 2 - 977 токенов

5. VectaraRAG
   
   Интересный вариант RAG. Данные загружаються в базу данных Vectra. Генерация идет с помощью сети Mockingbird 1.0 (Trained by Vectara. Optimized for RAG.).

   Так же можно в настройках базы выбрать llm OpenAI. Минусы - трассировка не работает (только один запрос VectaraQueryEngine). Ответы вышли не хуже чем от ChatGPT
     
